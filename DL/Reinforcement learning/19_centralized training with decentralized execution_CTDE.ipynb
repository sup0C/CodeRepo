{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7daa6d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import rl_utils\n",
    "import gym\n",
    "import multiagent_particle_envs.multiagent.scenarios as scenarios\n",
    "from multiagent_particle_envs.multiagent.environment import MultiAgentEnv\n",
    "\n",
    "# 下列代码是下载代码运行所需的环境和一些库\n",
    "# !git clone https://github.com/boyu-ai/multiagent-particle-envs.git --quiet\n",
    "# !pip install -e multiagent-particle-envs\n",
    "sys.path.append(\"multiagent_particle_envs\")\n",
    "# # 由于multiagent-pariticle-env底层的实现有一些版本问题,因此gym需要改为可用的版本\n",
    "# !pip install --upgrade gym==0.10.5 -q\n",
    "\n",
    "\n",
    "# import multiagent.scenarios as scenarios\n",
    "# from multiagent.environment import MultiAgentEnv\n",
    "\n",
    "def make_env(scenario_name):\n",
    "    # 从环境文件脚本中创建环境\n",
    "    scenario = scenarios.load(scenario_name + \".py\").Scenario()\n",
    "    world = scenario.make_world()\n",
    "    env = MultiAgentEnv(world, scenario.reset_world, scenario.reward,\n",
    "                        scenario.observation)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7072b837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove MultiagentSimple-v0 from registry\n",
      "Remove MultiagentSimpleSpeakerListener-v0 from registry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnol\\AppData\\Local\\Temp\\ipykernel_13752\\3523482564.py:111: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  torch.tensor([states[i]], dtype=torch.float, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100, [-130.2920736418247, 28.870750782083874, 28.870750782083874]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\editor\\pythonProject\\pythonProject1\\RL\\rl_utils.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(state), action, reward, np.array(next_state), done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 200, [-149.37310828855738, 0.6598878894255971, 0.6598878894255971]\n",
      "Episode: 300, [-100.01855786205203, 11.255147264867446, 11.255147264867446]\n",
      "Episode: 400, [-13.42152142258709, -0.31814245251758144, -0.31814245251758144]\n",
      "Episode: 500, [-13.684616034241516, -5.057439543411774, -5.057439543411774]\n",
      "Episode: 600, [-12.790554479281036, -4.515918123938338, -4.515918123938338]\n",
      "Episode: 700, [-11.701905298255825, 0.3880605447013667, 0.3880605447013667]\n",
      "Episode: 800, [-11.034757485924889, -0.5243662525356536, -0.5243662525356536]\n",
      "Episode: 900, [-9.909219518861036, 6.080776355617091, 6.080776355617091]\n",
      "Episode: 1000, [-10.142641762998494, 6.670854873125692, 6.670854873125692]\n",
      "Episode: 1100, [-10.422698301796363, 6.88165782836697, 6.88165782836697]\n",
      "Episode: 1200, [-10.739689680173095, 6.857726022023858, 6.857726022023858]\n",
      "Episode: 1300, [-9.030894614139745, 6.792866820992736, 6.792866820992736]\n",
      "Episode: 1400, [-9.772593245730235, 6.373619731111862, 6.373619731111862]\n",
      "Episode: 1500, [-9.758306722971867, 6.364805560728354, 6.364805560728354]\n",
      "Episode: 1600, [-8.541493695481337, 5.915409264841903, 5.915409264841903]\n",
      "Episode: 1700, [-8.61611482448795, 5.596577007525696, 5.596577007525696]\n",
      "Episode: 1800, [-8.686466567168669, 5.330009144885766, 5.330009144885766]\n",
      "Episode: 1900, [-8.95469469021823, 6.265913403221752, 6.265913403221752]\n",
      "Episode: 2000, [-7.059644494426423, 4.461068085008324, 4.461068085008324]\n",
      "Episode: 2100, [-8.0055310496882, 4.553351113863964, 4.553351113863964]\n",
      "Episode: 2200, [-8.288003337305414, 5.184072342869225, 5.184072342869225]\n",
      "Episode: 2300, [-8.67250590186953, 5.215915679015443, 5.215915679015443]\n",
      "Episode: 2400, [-7.479691554186084, 5.242770763834556, 5.242770763834556]\n",
      "Episode: 2500, [-7.680289952603912, 4.730632872449542, 4.730632872449542]\n",
      "Episode: 2600, [-8.553139696276551, 5.736023597311419, 5.736023597311419]\n",
      "Episode: 2700, [-8.074611966919754, 4.962259666112449, 4.962259666112449]\n",
      "Episode: 2800, [-8.147973124955545, 5.051711770538157, 5.051711770538157]\n",
      "Episode: 2900, [-7.902245751991282, 5.06639989684885, 5.06639989684885]\n",
      "Episode: 3000, [-7.404732761237097, 4.637762840234914, 4.637762840234914]\n",
      "Episode: 3100, [-8.105205114081127, 4.836824838593216, 4.836824838593216]\n",
      "Episode: 3200, [-8.703423195319614, 4.7995102698490175, 4.7995102698490175]\n",
      "Episode: 3300, [-9.908063429964878, 6.634204537666524, 6.634204537666524]\n",
      "Episode: 3400, [-8.836513276577495, 5.339722119115536, 5.339722119115536]\n",
      "Episode: 3500, [-8.177006607856612, 5.077666244871462, 5.077666244871462]\n",
      "Episode: 3600, [-8.24470544422675, 5.470757657746186, 5.470757657746186]\n",
      "Episode: 3700, [-8.560559156968624, 5.195543662830965, 5.195543662830965]\n",
      "Episode: 3800, [-8.153725336459614, 5.038971228260294, 5.038971228260294]\n",
      "Episode: 3900, [-8.660398627505032, 5.372683842960887, 5.372683842960887]\n",
      "Episode: 4000, [-7.83426522843664, 4.999346419057492, 4.999346419057492]\n",
      "Episode: 4100, [-7.760837160062593, 5.049990806268669, 5.049990806268669]\n",
      "Episode: 4200, [-8.531286990493456, 5.3648670236951705, 5.3648670236951705]\n",
      "Episode: 4300, [-9.279261692347543, 5.573906240761078, 5.573906240761078]\n",
      "Episode: 4400, [-9.679690937590252, 5.52858812868336, 5.52858812868336]\n",
      "Episode: 4500, [-9.555642917975714, 5.180485025700514, 5.180485025700514]\n",
      "Episode: 4600, [-9.465906222301625, 5.664800935172179, 5.664800935172179]\n",
      "Episode: 4700, [-10.210337395205176, 6.228954884735204, 6.228954884735204]\n",
      "Episode: 4800, [-10.36406171196737, 6.582256241504965, 6.582256241504965]\n",
      "Episode: 4900, [-10.449569567967457, 6.461646148562538, 6.461646148562538]\n",
      "Episode: 5000, [-10.667589038901296, 6.38326357673811, 6.38326357673811]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 让 DDPG 可以适用于离散动作空间的 Gumbel Softmax 采样的相关函数。\n",
    "def onehot_from_logits(logits, eps=0.01):\n",
    "    ''' 生成最优动作的独热（one-hot）形式 '''\n",
    "    # logits.shape=torch.Size([1, 5]) \n",
    "    argmax_acs = (logits == logits.max(1, keepdim=True)[0]).float()  # tensor([[0., 0., 0., 0., 1.]]\n",
    "    # 生成随机动作,转换成独热形式\n",
    "    rand_acs = torch.autograd.Variable(\n",
    "        torch.eye(logits.shape[1])[[np.random.choice(range(logits.shape[1]), size=logits.shape[0])]],requires_grad=False).to(logits.device)  # 创建一个全是1的向量，然后随机从中选一个索引\n",
    "    # 通过epsilon-贪婪算法来选择用哪个动作\n",
    "    a=torch.stack([argmax_acs[i] if r > eps else rand_acs[i] for i, r in enumerate(torch.rand(logits.shape[0]))])\n",
    "    return a # tensor([[0., 0., 0., 1., 0.]],shape=(1,5)\n",
    "\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-20, tens_type=torch.FloatTensor):\n",
    "    \"\"\"从Gumbel(0,1)分布中采样\"\"\"\n",
    "    U = torch.autograd.Variable(tens_type(*shape).uniform_(),requires_grad=False)\n",
    "    return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    \"\"\" 从Gumbel-Softmax分布中采样\"\"\"\n",
    "    y = logits + sample_gumbel(logits.shape, tens_type=type(logits.data)).to(logits.device)\n",
    "    return F.softmax(y / temperature, dim=1)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, temperature=1.0):\n",
    "    \"\"\"从Gumbel-Softmax分布中采样,并进行离散化\"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    y_hard = onehot_from_logits(y)\n",
    "    y = (y_hard.to(logits.device) - y).detach() + y\n",
    "    # 返回一个y_hard的独热量,但是它的梯度是y,我们既能够得到一个与环境交互的离散动作,又可以\n",
    "    # 正确地反传梯度\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "# 单智能体 DDPG。其中包含 Actor 网络与 Critic 网络，以及计算动作的函数\n",
    "class TwoLayerFC(torch.nn.Module):\n",
    "    def __init__(self, num_in, num_out, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(num_in, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim, num_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "class DDPG:\n",
    "    ''' DDPG算法 '''\n",
    "    def __init__(self, state_dim, action_dim, critic_input_dim, hidden_dim,actor_lr, critic_lr, device):\n",
    "        self.actor = TwoLayerFC(state_dim, action_dim, hidden_dim).to(device)\n",
    "        self.target_actor = TwoLayerFC(state_dim, action_dim,hidden_dim).to(device)\n",
    "        self.critic = TwoLayerFC(critic_input_dim, 1, hidden_dim).to(device)\n",
    "        self.target_critic = TwoLayerFC(critic_input_dim, 1,hidden_dim).to(device)\n",
    "        self.target_critic.load_state_dict(self.critic.state_dict())\n",
    "        self.target_actor.load_state_dict(self.actor.state_dict())\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),lr=actor_lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),lr=critic_lr)\n",
    "\n",
    "    def take_action(self, state, explore=False):\n",
    "        action = self.actor(state)\n",
    "        if explore:\n",
    "            action = gumbel_softmax(action)\n",
    "        else:\n",
    "            action = onehot_from_logits(action)\n",
    "        return action.detach().cpu().numpy()[0]  # action.shape=(1,5)\n",
    "\n",
    "    def soft_update(self, net, target_net, tau):\n",
    "        for param_target, param in zip(target_net.parameters(),net.parameters()):\n",
    "            param_target.data.copy_(param_target.data * (1.0 - tau) +param.data * tau)\n",
    "            \n",
    "            \n",
    "#  MADDPG 类\n",
    "class MADDPG:\n",
    "    def __init__(self, env, device, actor_lr, critic_lr, hidden_dim,state_dims, action_dims, critic_input_dim, gamma, tau):\n",
    "        self.agents = []\n",
    "        for i in range(len(env.agents)):\n",
    "            self.agents.append(\n",
    "                DDPG(state_dims[i], action_dims[i], critic_input_dim,hidden_dim, actor_lr, critic_lr, device))\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.critic_criterion = torch.nn.MSELoss()\n",
    "        self.device = device\n",
    "\n",
    "    @property\n",
    "    def policies(self):\n",
    "        return [agt.actor for agt in self.agents]\n",
    "\n",
    "    @property\n",
    "    def target_policies(self):\n",
    "        return [agt.target_actor for agt in self.agents]\n",
    "\n",
    "    def take_action(self, states, explore):\n",
    "        states = [torch.tensor([states[i]], dtype=torch.float, device=self.device)\n",
    "            for i in range(len(env.agents))]\n",
    "        return [agent.take_action(state, explore) for agent, state in zip(self.agents, states)]\n",
    "\n",
    "    def update(self, sample, i_agent):\n",
    "        '''  \n",
    "        i_agent: 第几个智能体\n",
    "        '''\n",
    "        obs, act, rew, next_obs, done = sample\n",
    "        cur_agent = self.agents[i_agent]\n",
    "\n",
    "        cur_agent.critic_optimizer.zero_grad()\n",
    "        all_target_act = [onehot_from_logits(pi(_next_obs))\n",
    "            for pi, _next_obs in zip(self.target_policies, next_obs)]\n",
    "        target_critic_input = torch.cat((*next_obs, *all_target_act), dim=1)\n",
    "        target_critic_value = rew[i_agent].view(-1, 1) + self.gamma * cur_agent.target_critic(\n",
    "                target_critic_input) * (1 - done[i_agent].view(-1, 1))\n",
    "        critic_input = torch.cat((*obs, *act), dim=1)\n",
    "        critic_value = cur_agent.critic(critic_input)\n",
    "        critic_loss = self.critic_criterion(critic_value,target_critic_value.detach())\n",
    "        critic_loss.backward()\n",
    "        cur_agent.critic_optimizer.step()\n",
    "\n",
    "        cur_agent.actor_optimizer.zero_grad()\n",
    "        cur_actor_out = cur_agent.actor(obs[i_agent])\n",
    "        cur_act_vf_in = gumbel_softmax(cur_actor_out)\n",
    "        all_actor_acs = []\n",
    "        for i, (pi, _obs) in enumerate(zip(self.policies, obs)):\n",
    "            if i == i_agent:\n",
    "                all_actor_acs.append(cur_act_vf_in)\n",
    "            else:\n",
    "                all_actor_acs.append(onehot_from_logits(pi(_obs)))\n",
    "        vf_in = torch.cat((*obs, *all_actor_acs), dim=1)\n",
    "        actor_loss = -cur_agent.critic(vf_in).mean()\n",
    "        actor_loss += (cur_actor_out**2).mean() * 1e-3\n",
    "        actor_loss.backward()\n",
    "        cur_agent.actor_optimizer.step()\n",
    "\n",
    "    def update_all_targets(self):\n",
    "        for agt in self.agents:\n",
    "            agt.soft_update(agt.actor, agt.target_actor, self.tau)\n",
    "            agt.soft_update(agt.critic, agt.target_critic, self.tau)\n",
    "            \n",
    "\n",
    "            \n",
    "num_episodes = 5000\n",
    "episode_length = 25  # 每条序列的最大长度\n",
    "buffer_size = 100000\n",
    "hidden_dim = 64\n",
    "actor_lr = 1e-2\n",
    "critic_lr = 1e-2\n",
    "gamma = 0.95\n",
    "tau = 1e-2\n",
    "batch_size = 1024\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "update_interval = 100\n",
    "minimal_size = 4000\n",
    "\n",
    "env_id = \"simple_adversary\"\n",
    "env = make_env(env_id)\n",
    "replay_buffer = rl_utils.ReplayBuffer(buffer_size)\n",
    "\n",
    "state_dims = []\n",
    "action_dims = []\n",
    "for action_space in env.action_space:  # [Discrete(5), Discrete(5), Discrete(5)] ，每个agent有5个动作\n",
    "    action_dims.append(action_space.n) # [5, 5, 5]\n",
    "for state_space in env.observation_space: # [Box(8,), Box(10,), Box(10,)]\n",
    "    state_dims.append(state_space.shape[0]) # [8, 10, 10]\n",
    "critic_input_dim = sum(state_dims) + sum(action_dims)  # 43  \n",
    "\n",
    "maddpg = MADDPG(env, device, actor_lr, critic_lr, hidden_dim, state_dims,\n",
    "                action_dims, critic_input_dim, gamma, tau)\n",
    "\n",
    "\n",
    "            \n",
    "# 评估策略的方法\n",
    "def evaluate(env_id, maddpg, n_episode=10, episode_length=25):\n",
    "    # 对学习的策略进行评估,此时不会进行探索\n",
    "    env = make_env(env_id)\n",
    "    returns = np.zeros(len(env.agents))\n",
    "    for _ in range(n_episode):\n",
    "        obs = env.reset()\n",
    "        for t_i in range(episode_length):  # episode_length是每条序列的最大长度\n",
    "            actions = maddpg.take_action(obs, explore=False)\n",
    "            obs, rew, done, info = env.step(actions)  # res.shape=(3)\n",
    "            rew = np.array(rew)\n",
    "            returns += rew / n_episode \n",
    "    return returns.tolist() # 最终返回的returns为n_episode次rew*episode_length的平均return\n",
    "\n",
    "\n",
    "return_list = []  # 记录每一轮的回报（return）\n",
    "total_step = 0\n",
    "for i_episode in range(num_episodes):\n",
    "    state = env.reset()  # 三个状态，shape分别为(8,) (10,) (10,)\n",
    "    # ep_returns = np.zeros(len(env.agents))\n",
    "    for e_i in range(episode_length):\n",
    "        actions = maddpg.take_action(state, explore=True)\n",
    "        next_state, reward, done, _ = env.step(actions)\n",
    "        replay_buffer.add(state, actions, reward, next_state, done)\n",
    "        state = next_state\n",
    "\n",
    "        total_step += 1\n",
    "        if replay_buffer.size() >= minimal_size and total_step % update_interval == 0:\n",
    "            sample = replay_buffer.sample(batch_size)  # 采样回来是batch个数据元组\n",
    "            def stack_array(x):\n",
    "                '''\n",
    "                将送进来的数据最后变为shape=(智能体数量，a_dim)\n",
    "                '''\n",
    "                rearranged = [[sub_x[i] for sub_x in x] for i in range(len(x[0]))]\n",
    "                return [torch.FloatTensor(np.vstack(aa)).to(device) for aa in rearranged]\n",
    "            sample = [stack_array(x) for x in sample]\n",
    "            for a_i in range(len(env.agents)):\n",
    "                maddpg.update(sample, a_i)\n",
    "            maddpg.update_all_targets()\n",
    "    if (i_episode + 1) % 100 == 0:\n",
    "        # 一共其实就50个点，但是将坐标轴的间距扩大了100倍\n",
    "        ep_returns = evaluate(env_id, maddpg, n_episode=100)  \n",
    "        return_list.append(ep_returns)\n",
    "        print(f\"Episode: {i_episode+1}, {ep_returns}\")\n",
    "        \n",
    "        \n",
    "return_array = np.array(return_list)\n",
    "for i, agent_name in enumerate([\"adversary_0\", \"agent_0\", \"agent_1\"]):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(return_array.shape[0]) * 100,rl_utils.moving_average(return_array[:, i], 9))\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.ylabel(\"Returns\")\n",
    "    plt.title(f\"{agent_name} by MADDPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5c6d704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100, [-155.32622861201475, 29.43106159528153, 29.43106159528153]\n",
      "Episode: 200, [-160.61369680025945, 3.0477623502433535, 3.0477623502433535]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    206\u001b[0m         sample \u001b[38;5;241m=\u001b[39m [stack_array(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m sample]\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m a_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(env\u001b[38;5;241m.\u001b[39magents)):\n\u001b[1;32m--> 208\u001b[0m             \u001b[43mmaddpg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m         maddpg\u001b[38;5;241m.\u001b[39mupdate_all_targets()\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i_episode \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36mMADDPG.update\u001b[1;34m(self, sample, i_agent)\u001b[0m\n\u001b[0;32m    106\u001b[0m cur_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents[i_agent]\n\u001b[0;32m    108\u001b[0m cur_agent\u001b[38;5;241m.\u001b[39mcritic_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 109\u001b[0m all_target_act \u001b[38;5;241m=\u001b[39m [onehot_from_logits(pi(_next_obs))\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pi, _next_obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_policies, next_obs)]\n\u001b[0;32m    111\u001b[0m target_critic_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;241m*\u001b[39mnext_obs, \u001b[38;5;241m*\u001b[39mall_target_act), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    112\u001b[0m target_critic_value \u001b[38;5;241m=\u001b[39m rew[i_agent]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m cur_agent\u001b[38;5;241m.\u001b[39mtarget_critic(\n\u001b[0;32m    113\u001b[0m         target_critic_input) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m done[i_agent]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    106\u001b[0m cur_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents[i_agent]\n\u001b[0;32m    108\u001b[0m cur_agent\u001b[38;5;241m.\u001b[39mcritic_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 109\u001b[0m all_target_act \u001b[38;5;241m=\u001b[39m [\u001b[43monehot_from_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_next_obs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pi, _next_obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_policies, next_obs)]\n\u001b[0;32m    111\u001b[0m target_critic_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;241m*\u001b[39mnext_obs, \u001b[38;5;241m*\u001b[39mall_target_act), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    112\u001b[0m target_critic_value \u001b[38;5;241m=\u001b[39m rew[i_agent]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m cur_agent\u001b[38;5;241m.\u001b[39mtarget_critic(\n\u001b[0;32m    113\u001b[0m         target_critic_input) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m done[i_agent]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36monehot_from_logits\u001b[1;34m(logits, eps)\u001b[0m\n\u001b[0;32m      7\u001b[0m rand_acs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mVariable(\n\u001b[0;32m      8\u001b[0m     torch\u001b[38;5;241m.\u001b[39meye(logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])[[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), size\u001b[38;5;241m=\u001b[39mlogits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]],requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(logits\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# 创建一个全是1的向量，然后随机从中选一个索引\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 通过epsilon-贪婪算法来选择用哪个动作\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m a\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mstack([argmax_acs[i] \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;241m>\u001b[39m eps \u001b[38;5;28;01melse\u001b[39;00m rand_acs[i] \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(torch\u001b[38;5;241m.\u001b[39mrand(logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m rand_acs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mVariable(\n\u001b[0;32m      8\u001b[0m     torch\u001b[38;5;241m.\u001b[39meye(logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])[[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mrange\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), size\u001b[38;5;241m=\u001b[39mlogits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]],requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(logits\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# 创建一个全是1的向量，然后随机从中选一个索引\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 通过epsilon-贪婪算法来选择用哪个动作\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m a\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mstack([argmax_acs[i] \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m rand_acs[i] \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(torch\u001b[38;5;241m.\u001b[39mrand(logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 让 DDPG 可以适用于离散动作空间的 Gumbel Softmax 采样的相关函数。\n",
    "def onehot_from_logits(logits, eps=0.01):\n",
    "    ''' 生成最优动作的独热（one-hot）形式 '''\n",
    "    # logits.shape=torch.Size([1, 5]) \n",
    "    argmax_acs = (logits == logits.max(1, keepdim=True)[0]).float()  # tensor([[0., 0., 0., 0., 1.]]\n",
    "    # 生成随机动作,转换成独热形式\n",
    "    rand_acs = torch.autograd.Variable(\n",
    "        torch.eye(logits.shape[1])[[np.random.choice(range(logits.shape[1]), size=logits.shape[0])]],requires_grad=False).to(logits.device)  # 创建一个全是1的向量，然后随机从中选一个索引\n",
    "    # 通过epsilon-贪婪算法来选择用哪个动作\n",
    "    a=torch.stack([argmax_acs[i] if r > eps else rand_acs[i] for i, r in enumerate(torch.rand(logits.shape[0]))])\n",
    "    return a # tensor([[0., 0., 0., 1., 0.]],shape=(1,5)\n",
    "\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-20, tens_type=torch.FloatTensor):\n",
    "    \"\"\"从Gumbel(0,1)分布中采样\"\"\"\n",
    "    U = torch.autograd.Variable(tens_type(*shape).uniform_(),requires_grad=False)\n",
    "    return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    \"\"\" 从Gumbel-Softmax分布中采样\"\"\"\n",
    "    y = logits + sample_gumbel(logits.shape, tens_type=type(logits.data)).to(logits.device)\n",
    "    return F.softmax(y / temperature, dim=1)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, temperature=1.0):\n",
    "    \"\"\"从Gumbel-Softmax分布中采样,并进行离散化\"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    y_hard = onehot_from_logits(y)\n",
    "    y = (y_hard.to(logits.device) - y).detach() + y\n",
    "    # 返回一个y_hard的独热量,但是它的梯度是y,我们既能够得到一个与环境交互的离散动作,又可以\n",
    "    # 正确地反传梯度\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "# 单智能体 DDPG。其中包含 Actor 网络与 Critic 网络，以及计算动作的函数\n",
    "class TwoLayerFC(torch.nn.Module):\n",
    "    def __init__(self, num_in, num_out, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(num_in, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim, num_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "class DDPG:\n",
    "    ''' DDPG算法 '''\n",
    "    def __init__(self, state_dim, action_dim, critic_input_dim, hidden_dim,actor_lr, critic_lr, device):\n",
    "        self.actor = TwoLayerFC(state_dim, action_dim, hidden_dim).to(device)\n",
    "        self.target_actor = TwoLayerFC(state_dim, action_dim,hidden_dim).to(device)\n",
    "        self.critic = TwoLayerFC(critic_input_dim, 1, hidden_dim).to(device)\n",
    "        self.target_critic = TwoLayerFC(critic_input_dim, 1,hidden_dim).to(device)\n",
    "        self.target_critic.load_state_dict(self.critic.state_dict())\n",
    "        self.target_actor.load_state_dict(self.actor.state_dict())\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),lr=actor_lr)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),lr=critic_lr)\n",
    "\n",
    "    def take_action(self, state, explore=False):\n",
    "        action = self.actor(state)\n",
    "        if explore:\n",
    "            action = gumbel_softmax(action)\n",
    "        else:\n",
    "            action = onehot_from_logits(action)\n",
    "        return action.detach().cpu().numpy()[0]  # action.shape=(1,5)\n",
    "\n",
    "    def soft_update(self, net, target_net, tau):\n",
    "        for param_target, param in zip(target_net.parameters(),net.parameters()):\n",
    "            param_target.data.copy_(param_target.data * (1.0 - tau) +param.data * tau)\n",
    "            \n",
    "            \n",
    "#  MADDPG 类\n",
    "class MADDPG:\n",
    "    def __init__(self, env, device, actor_lr, critic_lr, hidden_dim,state_dims, action_dims, critic_input_dim, gamma, tau):\n",
    "        self.agents = []\n",
    "        for i in range(len(env.agents)):\n",
    "            self.agents.append(\n",
    "                DDPG(state_dims[i], action_dims[i], critic_input_dim,hidden_dim, actor_lr, critic_lr, device))\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.critic_criterion = torch.nn.MSELoss()\n",
    "        self.device = device\n",
    "\n",
    "    @property\n",
    "    def policies(self):\n",
    "        return [agt.actor for agt in self.agents]\n",
    "\n",
    "    @property\n",
    "    def target_policies(self):\n",
    "        return [agt.target_actor for agt in self.agents]\n",
    "\n",
    "    def take_action(self, states, explore):\n",
    "        states = [torch.tensor([states[i]], dtype=torch.float, device=self.device)\n",
    "            for i in range(len(env.agents))]\n",
    "        return [agent.take_action(state, explore) for agent, state in zip(self.agents, states)]\n",
    "\n",
    "    def update(self, sample, i_agent):\n",
    "        '''  \n",
    "        i_agent: 第几个智能体\n",
    "        '''\n",
    "        obs, act, rew, next_obs, done = sample\n",
    "        cur_agent = self.agents[i_agent]\n",
    "\n",
    "        cur_agent.critic_optimizer.zero_grad()\n",
    "        all_target_act = [onehot_from_logits(pi(_next_obs))\n",
    "            for pi, _next_obs in zip(self.target_policies, next_obs)]\n",
    "        target_critic_input = torch.cat((*next_obs, *all_target_act), dim=1)\n",
    "        target_critic_value = rew[i_agent].view(-1, 1) + self.gamma * cur_agent.target_critic(\n",
    "                target_critic_input) * (1 - done[i_agent].view(-1, 1))\n",
    "        critic_input = torch.cat((*obs, *act), dim=1)\n",
    "        critic_value = cur_agent.critic(critic_input)\n",
    "        critic_loss = self.critic_criterion(critic_value,target_critic_value.detach())\n",
    "        critic_loss.backward()\n",
    "        cur_agent.critic_optimizer.step()\n",
    "\n",
    "        cur_agent.actor_optimizer.zero_grad()\n",
    "        cur_actor_out = cur_agent.actor(obs[i_agent])\n",
    "        cur_act_vf_in = gumbel_softmax(cur_actor_out)\n",
    "        all_actor_acs = []\n",
    "        for i, (pi, _obs) in enumerate(zip(self.policies, obs)):\n",
    "            if i == i_agent:\n",
    "                all_actor_acs.append(cur_act_vf_in)\n",
    "            else:\n",
    "                all_actor_acs.append(onehot_from_logits(pi(_obs)))\n",
    "        vf_in = torch.cat((*obs, *all_actor_acs), dim=1)\n",
    "        actor_loss = -cur_agent.critic(vf_in).mean()\n",
    "        actor_loss += (cur_actor_out**2).mean() * 1e-3\n",
    "        actor_loss.backward()\n",
    "        cur_agent.actor_optimizer.step()\n",
    "\n",
    "    def update_all_targets(self):\n",
    "        for agt in self.agents:\n",
    "            agt.soft_update(agt.actor, agt.target_actor, self.tau)\n",
    "            agt.soft_update(agt.critic, agt.target_critic, self.tau)\n",
    "            \n",
    "\n",
    "            \n",
    "num_episodes = 5000\n",
    "episode_length = 25  # 每条序列的最大长度\n",
    "buffer_size = 100000\n",
    "hidden_dim = 64\n",
    "actor_lr = 1e-2\n",
    "critic_lr = 1e-2\n",
    "gamma = 0.95\n",
    "tau = 1e-2\n",
    "batch_size = 1024\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "update_interval = 100\n",
    "minimal_size = 4000\n",
    "\n",
    "env_id = \"simple_adversary\"\n",
    "env = make_env(env_id)\n",
    "replay_buffer = rl_utils.ReplayBuffer(buffer_size)\n",
    "\n",
    "state_dims = []\n",
    "action_dims = []\n",
    "for action_space in env.action_space:  # [Discrete(5), Discrete(5), Discrete(5)] ，每个agent有5个动作\n",
    "    action_dims.append(action_space.n) # [5, 5, 5]\n",
    "for state_space in env.observation_space: # [Box(8,), Box(10,), Box(10,)]\n",
    "    state_dims.append(state_space.shape[0]) # [8, 10, 10]\n",
    "critic_input_dim = sum(state_dims) + sum(action_dims)  # 43  \n",
    "\n",
    "maddpg = MADDPG(env, device, actor_lr, critic_lr, hidden_dim, state_dims,\n",
    "                action_dims, critic_input_dim, gamma, tau)\n",
    "\n",
    "\n",
    "            \n",
    "# 评估策略的方法\n",
    "def evaluate(env_id, maddpg, n_episode=10, episode_length=25):\n",
    "    # 对学习的策略进行评估,此时不会进行探索\n",
    "    env = make_env(env_id)\n",
    "    returns = np.zeros(len(env.agents))\n",
    "    for _ in range(n_episode):\n",
    "        obs = env.reset()\n",
    "        for t_i in range(episode_length):  # episode_length是每条序列的最大长度\n",
    "            actions = maddpg.take_action(obs, explore=False)\n",
    "            obs, rew, done, info = env.step(actions)  # res.shape=(3)\n",
    "            rew = np.array(rew)\n",
    "            returns += rew / n_episode \n",
    "    return returns.tolist() # 最终返回的returns为n_episode次rew*episode_length的平均return\n",
    "\n",
    "\n",
    "return_list = []  # 记录每一轮的回报（return）\n",
    "total_step = 0\n",
    "for i_episode in range(num_episodes):\n",
    "    state = env.reset()  # 三个状态，shape分别为(8,) (10,) (10,)\n",
    "    # ep_returns = np.zeros(len(env.agents))\n",
    "    for e_i in range(episode_length):\n",
    "        actions = maddpg.take_action(state, explore=True)\n",
    "        next_state, reward, done, _ = env.step(actions)\n",
    "        replay_buffer.add(state, actions, reward, next_state, done)\n",
    "        state = next_state\n",
    "\n",
    "        total_step += 1\n",
    "        if replay_buffer.size() >= minimal_size and total_step % update_interval == 0:\n",
    "            sample = replay_buffer.sample(batch_size)  # 采样回来是batch个数据元组\n",
    "            def stack_array(x):\n",
    "                '''\n",
    "                将送进来的数据最后变为shape=(智能体数量，a_dim)\n",
    "                '''\n",
    "#                 # len(x[0]=3/智能体数量,len(x)=batch\n",
    "                rearranged = [[sub_x[i] for sub_x in x] for i in range(len(x[0]))] \n",
    "                return [torch.FloatTensor(np.vstack(aa)).to(device) for aa in rearranged]\n",
    "            sample = [stack_array(x) for x in sample]  # 这里的x分别是s,a,r,s`,done，他们第一个shape都为batch\n",
    "            for a_i in range(len(env.agents)):\n",
    "                maddpg.update(sample, a_i)\n",
    "            maddpg.update_all_targets()\n",
    "    if (i_episode + 1) % 100 == 0:\n",
    "        # 一共其实就50个点，但是将坐标轴的间距扩大了100倍\n",
    "        ep_returns = evaluate(env_id, maddpg, n_episode=100)  \n",
    "        return_list.append(ep_returns)\n",
    "        print(f\"Episode: {i_episode+1}, {ep_returns}\")\n",
    "        \n",
    "        \n",
    "return_array = np.array(return_list)\n",
    "for i, agent_name in enumerate([\"adversary_0\", \"agent_0\", \"agent_1\"]):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(return_array.shape[0]) * 100,rl_utils.moving_average(return_array[:, i], 9))\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.ylabel(\"Returns\")\n",
    "    plt.title(f\"{agent_name} by MADDPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b1251477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "sample=replay_buffer.sample(10)\n",
    "# a,b,c,d,e=sample\n",
    "# print(a.shape)\n",
    "# # print(b.shape)\n",
    "# # print(c.shape)\n",
    "# print(d.shape)\n",
    "# print(e)\n",
    "for x in sample:\n",
    "    print(len(x[0]))\n",
    "\n",
    "def stack_array(x):\n",
    "    '''\n",
    "    将送进来的数据最后变为shape=(智能体数量，a_dim)\n",
    "    '''\n",
    "    rearranged = [[sub_x[i] for sub_x in x] for i in range(len(x[0]))]\n",
    "    return [torch.FloatTensor(np.vstack(aa)).to(device) for aa in rearranged]\n",
    "sample = [stack_array(x) for x in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe6a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycharm_venv",
   "language": "python",
   "name": "pycharm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
