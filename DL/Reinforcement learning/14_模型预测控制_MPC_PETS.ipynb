{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e16ff7d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1, return: -890\n",
      "episode: 2, return: -996\n",
      "episode: 3, return: -1345\n",
      "episode: 4, return: -122\n",
      "episode: 5, return: -253\n",
      "episode: 6, return: -363\n",
      "episode: 7, return: -120\n",
      "episode: 8, return: -122\n",
      "episode: 9, return: -248\n",
      "episode: 10, return: -120\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import gym\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 交叉熵方法，其中将采用截断正态分布。\n",
    "class CEM:\n",
    "    def __init__(self, n_sequence, elite_ratio, fake_env, upper_bound,lower_bound):\n",
    "        self.n_sequence = n_sequence\n",
    "        self.elite_ratio = elite_ratio\n",
    "        self.upper_bound = upper_bound\n",
    "        self.lower_bound = lower_bound\n",
    "        self.fake_env = fake_env\n",
    "\n",
    "    def optimize(self, state, init_mean, init_var):\n",
    "        mean, var = init_mean, init_var\n",
    "        X = truncnorm(-2, 2, loc=np.zeros_like(mean), scale=np.ones_like(var))\n",
    "        state = np.tile(state, (self.n_sequence, 1))\n",
    "\n",
    "        for _ in range(5):\n",
    "            lb_dist, ub_dist = mean - self.lower_bound, self.upper_bound - mean\n",
    "            constrained_var = np.minimum(np.minimum(np.square(lb_dist / 2), np.square(ub_dist / 2)),var)\n",
    "            # 生成动作序列\n",
    "            action_sequences = [X.rvs() for _ in range(self.n_sequence)] * np.sqrt(constrained_var) + mean\n",
    "            # 计算每条动作序列的累积奖励\n",
    "            returns = self.fake_env.propagate(state, action_sequences)[:, 0]\n",
    "            # 选取累积奖励最高的若干条动作序列\n",
    "            elites = action_sequences[np.argsort(returns)][-int(self.elite_ratio * self.n_sequence):]\n",
    "            new_mean = np.mean(elites, axis=0)\n",
    "            new_var = np.var(elites, axis=0)\n",
    "            # 更新动作序列分布\n",
    "            mean = 0.1 * mean + 0.9 * new_mean\n",
    "            var = 0.1 * var + 0.9 * new_var\n",
    "\n",
    "        return mean\n",
    "    \n",
    "\n",
    "    \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device( \"cpu\")\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    ''' Swish激活函数 '''\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    ''' 初始化模型权重 '''\n",
    "    def truncated_normal_init(t, mean=0.0, std=0.01):\n",
    "        torch.nn.init.normal_(t, mean=mean, std=std)\n",
    "        while True:\n",
    "            cond = (t < mean - 2 * std) | (t > mean + 2 * std)  # 横轴区间（μ-2σ,μ+2σ）内的面积为95.449974%。\n",
    "            if not torch.sum(cond):  # 小概率not torch.sum(cond)为False，大概率为True\n",
    "                break  # break退出while循环\n",
    "            t = torch.where(cond,\n",
    "                torch.nn.init.normal_(torch.ones(t.shape, device=device),mean=mean,std=std), t)\n",
    "        return t\n",
    "\n",
    "    if type(m) == nn.Linear or isinstance(m, FCLayer):\n",
    "        truncated_normal_init(m.weight, std=1 / (2 * np.sqrt(m._input_dim)))\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "\n",
    "class FCLayer(nn.Module):\n",
    "    ''' 集成之后的全连接层 '''\n",
    "    def __init__(self, input_dim, output_dim, ensemble_size, activation):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self._input_dim, self._output_dim = input_dim, output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(ensemble_size, input_dim, output_dim).to(device))\n",
    "        self._activation = activation\n",
    "        self.bias = nn.Parameter(torch.Tensor(ensemble_size, output_dim).to(device))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._activation(torch.add(torch.bmm(x, self.weight), self.bias[:, None, :]))\n",
    "    \n",
    "    \n",
    "    \n",
    "# 使用高斯分布的概率模型来定义一个集成模型。\n",
    "class EnsembleModel(nn.Module):\n",
    "    ''' 环境模型集成 '''\n",
    "    def __init__(self,state_dim,action_dim,ensemble_size=5,learning_rate=1e-3):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        # 输出包括均值和方差,因此是状态与奖励维度之和的两倍\n",
    "        self._output_dim = (state_dim + 1) * 2\n",
    "        self._max_logvar = nn.Parameter((torch.ones(\n",
    "            (1, self._output_dim // 2)).float() / 2).to(device),requires_grad=False)\n",
    "        self._min_logvar = nn.Parameter((-torch.ones(\n",
    "            (1, self._output_dim // 2)).float() * 10).to(device),requires_grad=False)\n",
    "\n",
    "        self.layer1 = FCLayer(state_dim + action_dim, 200, ensemble_size,Swish())\n",
    "        self.layer2 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer3 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer4 = FCLayer(200, 200, ensemble_size, Swish())\n",
    "        self.layer5 = FCLayer(200, self._output_dim, ensemble_size, nn.Identity())\n",
    "        self.apply(init_weights)  # 初始化环境模型中的参数\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x, return_log_var=False):\n",
    "        ret = self.layer5(self.layer4(self.layer3(self.layer2(self.layer1(x)))))\n",
    "        mean = ret[:, :, :self._output_dim // 2]\n",
    "        # 在PETS算法中,将方差控制在最小值和最大值之间\n",
    "        logvar = self._max_logvar - F.softplus(self._max_logvar - ret[:, :, self._output_dim // 2:])\n",
    "        logvar = self._min_logvar + F.softplus(logvar - self._min_logvar)\n",
    "        return mean, logvar if return_log_var else torch.exp(logvar)\n",
    "\n",
    "    def loss(self, mean, logvar, labels, use_var_loss=True):\n",
    "        inverse_var = torch.exp(-logvar)\n",
    "        if use_var_loss:\n",
    "            mse_loss = torch.mean(torch.mean(torch.pow(mean - labels, 2) * inverse_var,dim=-1), dim=-1)\n",
    "            var_loss = torch.mean(torch.mean(logvar, dim=-1), dim=-1)\n",
    "            total_loss = torch.sum(mse_loss) + torch.sum(var_loss)\n",
    "        else:\n",
    "            mse_loss = torch.mean(torch.pow(mean - labels, 2), dim=(1, 2))\n",
    "            total_loss = torch.sum(mse_loss)\n",
    "        return total_loss, mse_loss\n",
    "\n",
    "    def train(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss += 0.01 * torch.sum(self._max_logvar) - 0.01 * torch.sum(self._min_logvar)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# 定义一个EnsembleDynamicsModel的类，把模型集成的训练设计得更加精细化。具体而言，我们并不会选择模型训练的轮数，\n",
    "# 而是在每次训练的时候将一部分数据单独取出来，用于验证模型的表现，在 5 次没有获得表现提升时就结束训练。\n",
    "class EnsembleDynamicsModel:\n",
    "    ''' 环境模型集成,加入精细化的训练 '''\n",
    "    def __init__(self, state_dim, action_dim, num_network=5):\n",
    "        self._num_network = num_network\n",
    "        self._state_dim, self._action_dim = state_dim, action_dim\n",
    "        self.model = EnsembleModel(state_dim,action_dim,ensemble_size=num_network)\n",
    "        self._epoch_since_last_update = 0\n",
    "\n",
    "    def train(self,inputs,labels,batch_size=64,holdout_ratio=0.1,max_iter=20):\n",
    "        # 设置训练集与验证集 ,两者比例为9:1\n",
    "        permutation = np.random.permutation(inputs.shape[0])\n",
    "        inputs, labels = inputs[permutation], labels[permutation]\n",
    "        num_holdout = int(inputs.shape[0] * holdout_ratio)\n",
    "        train_inputs, train_labels = inputs[num_holdout:], labels[num_holdout:]\n",
    "        holdout_inputs, holdout_labels = inputs[: num_holdout], labels[: num_holdout]\n",
    "        holdout_inputs = torch.from_numpy(holdout_inputs).float().to(device)\n",
    "        holdout_labels = torch.from_numpy(holdout_labels).float().to(device)\n",
    "        holdout_inputs = holdout_inputs[None, :, :].repeat([self._num_network, 1, 1])\n",
    "        holdout_labels = holdout_labels[None, :, :].repeat([self._num_network, 1, 1])\n",
    "\n",
    "        # 保留最好的结果\n",
    "        self._snapshots = {i: (None, 1e10) for i in range(self._num_network)}\n",
    "\n",
    "        for epoch in itertools.count():\n",
    "            # 定义每一个网络的训练数据\n",
    "            train_index = np.vstack([np.random.permutation(train_inputs.shape[0])\n",
    "                for _ in range(self._num_network) ])  # 输出shape=(self._num_network,train_inputs.shape[0])\n",
    "            # 所有真实数据都用来训练\n",
    "            for batch_start_pos in range(0, train_inputs.shape[0], batch_size):\n",
    "                batch_index = train_index[:, batch_start_pos:batch_start_pos +batch_size]\n",
    "                train_input = torch.from_numpy(train_inputs[batch_index]).float().to(device)\n",
    "                train_label = torch.from_numpy(train_labels[batch_index]).float().to(device)\n",
    "\n",
    "                mean, logvar = self.model(train_input, return_log_var=True)\n",
    "                loss, _ = self.model.loss(mean, logvar, train_label)\n",
    "                self.model.train(loss)\n",
    "\n",
    "            with torch.no_grad():  # 验证模型用验证集数据\n",
    "                mean, logvar = self.model(holdout_inputs, return_log_var=True)\n",
    "                _, holdout_losses = self.model.loss(mean,logvar,holdout_labels,use_var_loss=False)\n",
    "                holdout_losses = holdout_losses.cpu()\n",
    "                break_condition = self._save_best(epoch, holdout_losses)\n",
    "                if break_condition or epoch > max_iter:  # 结束训练\n",
    "                    break\n",
    "\n",
    "    def _save_best(self, epoch, losses, threshold=0.1):\n",
    "        updated = False\n",
    "        for i in range(len(losses)):\n",
    "            current = losses[i]\n",
    "            _, best = self._snapshots[i]\n",
    "            improvement = (best - current) / best\n",
    "            if improvement > threshold:\n",
    "                self._snapshots[i] = (epoch, current)\n",
    "                updated = True\n",
    "        self._epoch_since_last_update = 0 if updated else self._epoch_since_last_update + 1\n",
    "        return self._epoch_since_last_update > 5\n",
    "\n",
    "    def predict(self, inputs, batch_size=64):\n",
    "        mean, var = [], []\n",
    "        for i in range(0, inputs.shape[0], batch_size):\n",
    "            input = torch.from_numpy( inputs[i:min(i +batch_size, inputs.shape[0])]).float().to(device)\n",
    "            cur_mean, cur_var = self.model(input[None, :, :].repeat([self._num_network, 1, 1]),\n",
    "                                           return_log_var=False)\n",
    "            mean.append(cur_mean.detach().cpu().numpy())\n",
    "            var.append(cur_var.detach().cpu().numpy())\n",
    "        return np.hstack(mean), np.hstack(var)\n",
    "    \n",
    "    \n",
    "    \n",
    "# 定义一个FakeEnv，主要用于实现给定状态和动作，用模型集成来进行预测。该功能会用在 MPC 算法中。\n",
    "class FakeEnv:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def step(self, obs, act):\n",
    "        inputs = np.concatenate((obs, act), axis=-1)\n",
    "        ensemble_model_means, ensemble_model_vars = self.model.predict(inputs)\n",
    "        ensemble_model_means[:, :, 1:] += obs.numpy()\n",
    "        ensemble_model_stds = np.sqrt(ensemble_model_vars)\n",
    "        ensemble_samples = ensemble_model_means + np.random.normal(\n",
    "            size=ensemble_model_means.shape) * ensemble_model_stds\n",
    "\n",
    "        num_models, batch_size, _ = ensemble_model_means.shape\n",
    "        models_to_use = np.random.choice([i for i in range(self.model._num_network)], size=batch_size)\n",
    "        batch_inds = np.arange(0, batch_size)\n",
    "        samples = ensemble_samples[models_to_use, batch_inds]\n",
    "        rewards, next_obs = samples[:, :1], samples[:, 1:]\n",
    "        return rewards, next_obs\n",
    "\n",
    "    def propagate(self, obs, actions):\n",
    "        with torch.no_grad():\n",
    "            obs = np.copy(obs)\n",
    "            total_reward = np.expand_dims(np.zeros(obs.shape[0]), axis=-1)\n",
    "            obs, actions = torch.as_tensor(obs), torch.as_tensor(actions)\n",
    "            for i in range(actions.shape[1]):\n",
    "                action = torch.unsqueeze(actions[:, i], 1)\n",
    "                rewards, next_obs = self.step(obs, action)\n",
    "                total_reward += rewards\n",
    "                obs = torch.as_tensor(next_obs)\n",
    "            return total_reward\n",
    "        \n",
    "        \n",
    "        \n",
    "# 定义经验回放池的类Replay Buffer。与之前的章节对比，此处经验回放缓冲区会额外实现一个返回所有数据的函数。\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def return_all_samples(self):\n",
    "        all_transitions = list(self.buffer)\n",
    "        state, action, reward, next_state, done = zip(*all_transitions)\n",
    "        return np.array(state), action, reward, np.array(next_state), done\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# PETS 算法的主体部分\n",
    "class PETS:\n",
    "    ''' PETS算法 '''\n",
    "    def __init__(self, env, replay_buffer, n_sequence, elite_ratio,\n",
    "                 plan_horizon, num_episodes):\n",
    "        self._env = env\n",
    "        self._env_pool = replay_buffer\n",
    "\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        self._action_dim = env.action_space.shape[0]\n",
    "        self._model = EnsembleDynamicsModel(obs_dim, self._action_dim)\n",
    "        self._fake_env = FakeEnv(self._model)\n",
    "        self.upper_bound = env.action_space.high[0]\n",
    "        self.lower_bound = env.action_space.low[0]\n",
    "\n",
    "        self._cem = CEM(n_sequence, elite_ratio, self._fake_env,self.upper_bound, self.lower_bound)\n",
    "        self.plan_horizon = plan_horizon\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "    def train_model(self):\n",
    "        env_samples = self._env_pool.return_all_samples()\n",
    "        obs = env_samples[0]\n",
    "        actions = np.array(env_samples[1])\n",
    "        rewards = np.array(env_samples[2]).reshape(-1, 1)\n",
    "        next_obs = env_samples[3]\n",
    "        inputs = np.concatenate((obs, actions), axis=-1)\n",
    "        labels = np.concatenate((rewards, next_obs - obs), axis=-1)\n",
    "        self._model.train(inputs, labels)\n",
    "\n",
    "    def mpc(self):\n",
    "        mean = np.tile((self.upper_bound + self.lower_bound) / 2.0, self.plan_horizon)\n",
    "        var = np.tile(np.square(self.upper_bound - self.lower_bound) / 16,self.plan_horizon)\n",
    "        obs, done, episode_return = self._env.reset(), False, 0\n",
    "        while not done:\n",
    "            actions = self._cem.optimize(obs, mean, var)\n",
    "            action = actions[:self._action_dim]  # 选取第一个动作\n",
    "            next_obs, reward, done, _ = self._env.step(action)\n",
    "            self._env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "            mean = np.concatenate([np.copy(actions)[self._action_dim:],np.zeros(self._action_dim)])\n",
    "        return episode_return\n",
    "\n",
    "    def explore(self):\n",
    "        obs, done, episode_return = self._env.reset(), False, 0\n",
    "        while not done:\n",
    "            action = self._env.action_space.sample()\n",
    "            next_obs, reward, done, _ = self._env.step(action)\n",
    "            self._env_pool.add(obs, action, reward, next_obs, done)\n",
    "            obs = next_obs\n",
    "            episode_return += reward\n",
    "        return episode_return\n",
    "\n",
    "    def train(self):\n",
    "        return_list = []\n",
    "        explore_return = self.explore()  # 先进行随机策略的探索来收集一条序列的数据\n",
    "        print('episode: 1, return: %d' % explore_return)\n",
    "        return_list.append(explore_return)\n",
    "\n",
    "        for i_episode in range(self.num_episodes - 1):\n",
    "            self.train_model()\n",
    "            episode_return = self.mpc()\n",
    "            return_list.append(episode_return)\n",
    "            print('episode: %d, return: %d' % (i_episode + 2, episode_return))\n",
    "        return return_list\n",
    "    \n",
    "    \n",
    "    \n",
    "# 倒立摆环境\n",
    "buffer_size = 100000\n",
    "n_sequence = 50\n",
    "elite_ratio = 0.2\n",
    "plan_horizon = 25\n",
    "num_episodes = 10\n",
    "env_name = 'Pendulum-v0'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "replay_buffer = ReplayBuffer(buffer_size)\n",
    "pets = PETS(env, replay_buffer, n_sequence, elite_ratio, plan_horizon,num_episodes)\n",
    "return_list = pets.train()\n",
    "\n",
    "episodes_list = list(range(len(return_list)))\n",
    "plt.plot(episodes_list, return_list)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('PETS on {}'.format(env_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd0818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycharm_venv",
   "language": "python",
   "name": "pycharm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
