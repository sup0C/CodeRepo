# 上采样-Upsampling
# 由于在卷积过程中，特征图像变得很小(比如长宽变为原图像的1/32)，为了得到原图像大小的稠密像素预测，需进行上采样。
# 实现方式：1. 插值法；2. 反池化；3. 反卷积(转置卷积)-本质是通过训练来放大图片

# 关于GAN的研究分为两种，一种是在各种各样的问题中应用GAN，一种是试图稳定GAN的训练。

# GAN损失
#   生成器：需要计算噪声/生成图像向量与1之间的损失，生成向量的分类输出与真实label之间损失(ACGAN、infoGAN)。
#           输入condition(c)和输出c之间的损失，为了使得c和图像之间有强相关性(infoGAN)。
#   判别器：需要计算真实向量与1之间的损失，生成向量与1之间的损失。真实向量的分类输出与真实label之间损失(ACGAN、infoGAN)。
#          输入condition(c)和输出c之间的损失，为了使得c和图像之间有强相关性(infoGAN)。
# 0  GPU
# 1、查看gpu和cpu的数量
# gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
# cpus = tf.config.experimental.list_physical_devices(device_type='CPU')
# print(gpus, cpus)

# 2、设置GPU加速
# 2.1 第一种：限制使用的gpu，没有限制消耗内存的大小：
#    通过 tf.config.experimental.set_visible_devices 。
#    可以设置当前程序可见的设备范围（当前程序只会使用自己可见的设备，不可见的设备不会被当前程序使用。
#    使用部分gpu加速。如下面使用gpu设备0，1
# gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
# tf.config.experimental.set_visible_devices(devices=gpus[0:2], device_type='GPU')

# 2.2 第二种：动态申请显存，仅在需要时申请显存空间。
#     通过 tf.config.experimental.set_memory_growth 将GPU的显存使用策略设置为“仅在需要时申请显存空间”。
#     以下代码将所有GPU设置为仅在需要时申请显存空间：
# gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
# for gpu in gpus:
#     tf.config.experimental.set_memory_growth(gpu, True)

# 2.3 第三种：限制使用的gpu，并且限制使用的内存大小。
#     通过 tf.config.experimental.set_virtual_device_configuration 选项
#     并传入 tf.config.experimental.VirtualDeviceConfiguration 实例，设置TensorFlow固定消耗 GPU:0 的1GB显存
# gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
# tf.config.experimental.set_virtual_device_configuration(
#     gpus[0],
#     [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])


# 3、单GPU模拟多GPU环境
#     当我们的本地开发环境只有一个GPU，但却需要编写多GPU的程序在工作站上进行训练任务时，
#     TensorFlow为我们提供了一个方便的功能，可以让我们在本地开发环境中建立多个模拟GPU，
#     从而让多GPU的程序调试变得更加方便。以下代码在实体GPU GPU:0 的基础上建立了两个显存均为2GB的虚拟GPU。
# gpus = tf.config.experimental.list_physical_devices('GPU')
# print(gpus)
# tf.config.experimental.set_virtual_device_configuration(
#      gpus[0],
#      [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048),
#       tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])
# gpus = tf.config.experimental.list_physical_devices('GPU')
# print(gpus)


# 1 自编码器
# 含义
#   使用自身的高阶特征编码自己，是一种神经网络，输入与输出一致，目标是利用稀疏的高阶特征重新组合来重构自己；
#    是一种数据的压缩算法，其中数据的压缩和解压函数是与数据相关的、有损的、从样本中自动学习的，
# 应用：数据去燥、降维、图像生成



# 2 变分自编码器(VAE)
# 可以随机生成隐含变量，提高网络的泛化能力，比普通的自动编码器好，缺点是生成的图片会有点模糊

# 3 GAN-Generative Adversarial Networks
# GAN是一种深度学习模型，是近年来复杂分布上无监督学习最具前景的方法之一，16年，GAN热潮席卷AI领域顶级会议，从ICLR到NIPS。
# 机器学习的模型可大体分为两类， 生成模型和判别模型。
# 判别模型需要输入变量，通过某种模型来预测。生成模型是给定某种隐含信息，来随机产生观测数据。
# 原理
#   包括两部分。生成器和判别器。生成器主要用来学习真实图像分布从而让自身生成的图像更加真实，以骗过判别器；
#   判别器对接收的图片进行真假判别；随着时间推移，生成器和判别器都在不断地进行对抗。最终达到一个平衡，生成器生成的图像接近于真实图像分布，
#   判别器无法判断，无论对于真假样本，输出概率均为0.5，相当于随机猜测类别。最终得到一个生成模型G，可以用来生成图像。
# 生成器-G
#   对于生成器传给判别器的生成图片，生成器希望辨别器打上标签0。
#   输入为噪声,计算生成图像和1之间的损失
# 判别器-D
#   对于给定的真实图像，打上标签1,；对于给定的生成图像，打上标签0。
#   两个D，输入分别为G生成的图像和真实图像；输出为size为1的一个标量，当G训练好时，D无论输入谁，输出都为0.5
#   NOTE：对于两个D，有两个损失-真实图像和1之间的损失、虚假图像和0的损失，最后两个损失相加返回；
# 应用领域：图像生成、图像增强、风格化、艺术的图像创作
# 缺点
#   生成图像是随机的，不可预测，无法控制网络输出特定图片，生成目标不明确，可控性不强。



# 4 DCGAN-Deep Convolutional Generative Adversarial Networks
# 将CNN和原始的GAN结合，即生成和判别模型都使用了深度卷积网络的生成对抗网络，对CNN结构做了一些改变，以提高样本的质量和收敛的速度。
# 论文：Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks
# 论文中网络的设计技巧
#   1 取消所有pooling层，G网络中使用转置卷积上采样，D网络中加入stride卷积代替pooling
#   2 去掉FC层，使网络变为全卷积网络
#   3 G网络中ReLU作为激活函数，最后一层使用tanh
#   4 D网络使用LeakyReLU作为激活函数
#   5 在G和D网络中都使用batchnorm，解决初始化差问题、将梯度传播到每一层、防止G网络将所有样本收敛到同一个点。
#   6 将BN引用到所有层会导致样本震荡和模型不稳定，因此在G的输出层和D的输入层不采用BN。
#   7 采用Adam优化器：bata1-一阶矩估计的指数衰减率的值为0.5
#   8 论文参数：LeakyReLU的斜率为0.2；LearningRate=0.0002；batch_size=128
# 生成器-G
#   对于生成器传给判别器的生成图片，生成器希望辨别器打上标签0。
#   输入为噪声,计算生成图像和1之间的损失
# 判别器-D
#   两个D，输入分别为生成图像和真实图像；
#   两个损失-真实和1*0.9(近似为1)之间的损失、虚假和1*0.1(近似为0)的损失，最后两个损失相加返回



# 5 cGAN-conditional GAN
#   解决了原始GAN不能生成具有特定属性图片的问题。CGAN通过在生成器和判别器中绝使用标签信息进行训练，可产生特定标签的数据。
#   将无监督学习改为有监督学习，使得网络可更好地被掌控。
#   核心在于将特征属性信息y融入生成器G和判别器D中，属性y可以是任何标签信息，如图像类型，人脸表情等。
# 特点
#   生成器和判别器的输入比普通GAN都多了label信息的输入，但都没有定义label损失，仅仅将label信息与图片/噪声信息融合在一起。
# 缺点
#   生成图像边缘模糊，分辨率低，但为cycle-GAN开辟了道路。
#   在CGAN中，附加参数c(如标签等)在语义上假设是已知的，在训练时必须提供它。
# 生成器-G
#   输入为噪声和真实标签,将标签embedding为和噪声相同的尺寸，然后concatenate融合、卷积、输出；计算生成图像和1之间的损失
# 判别器-D
#   两个D，输入分别为生成图像和真实标签、真实图像和真实标签；输出分别为分类别结果；两个损失-真实和1之间的损失、虚假和0的损失，最后两个损失相加返回



# 6 ACGAN
#   ACGAN是条件GAN的另一种实现，既使用标签信息进行训练，同时也重建标签信息
# 生成器
#     包含class和Noise两部分，class为训练数据标签信息，Noise为随机向量，将两者拼接，输出为图片(channel，height，width)
# 判别器
#     输入为真实和生成图片，输出为两部分：一是源数据的真假判断，(batchsize,1)；二是输入数据的分类结果，(batchsize,class_num)。
#     判别器的最后一层有两个并列的全连接层，分别得到这两个部分的输出结果(真假判断张量和分类结果张量)。
# 损失函数
#     判别器：分类准确并可分辨真假；   生成器：分类准确并使判别器不能分辨真假。
# 生成器-G
#   输入为噪声和真实标签,将标签embedding为和噪声相同的尺寸，然后concatenate融合、卷积、输出；
#   损失：两个损失相加返回。计算生成图像和1之间的损失；判别器对生成图像的label输出与真实label损失。
# 判别器-D
#   两个D，输入分别为生成图像和真实图像；输出分别为D1和D2的真假判别与分类判别向量；
#   三个损失(两个真假判别和一个分类判别)：真实和1之间的损失、虚假和0的损失，D对真实图像的label判断输出和真实label。三个相加返回




# 7 infoGAN
#   在CGAN中，生成器,G(z,c)有一个附加参数c(如标签等,为条件变量)在语义上假设是已知的，在训练时必须提供它。
#   在infoGAN中，假设c不知道，所以为c做出一个先验，并根据数据推断它。通过使用连续的和离散的隐含因子来学习可分解的特征。
#   若为表征学习的角度来看GAN模型，会发现在生成器使用噪声z的时候没有加任何的限制，所以在以一种高度混合的方式使用z，
#   z的任何一个维度都没有明显的表示一个特征，所以在数据生成过程中，我们无法得知什么样的噪声z可以用来生成数字1/3等，
#   这在一定程度上限制了我们对GAN的使用。

#   在生成器中除了原先的噪声z还增加了一个隐含编码c，所谓infoGAN，其中info代表互动信息，表示生成数据x与隐藏编码c
#   之间关联程度的大小，为了使得x与c之间关联密切，所以我们需要最大化互信息的值，以此对原始GAN模型的值函数做了修改，
#   相当于加了一个互信息的正则化项。

# 互信息
#   可以将互信息看成当观测到y值而造成x的不确定性的减小，若x，y是相互独立没有相关性，则互信息的值为0，即已知y的
#   情况下推测x与x的原始分布没有区别；若x、y有相关性，即互信息的值大于0，那么已知y的情况下，就知道哪些x的值出现的概率更大。

#   该网络所要达到的目标是通过非监督学习得到可分解的特征表示，使用GAN加上最大化生成的图片和输入编码之间的互信息。
#   最大的好处是可以不需要监督学习，而且不需要额外的计算花销就能得到可解释的特征。

#   该网络的出发点就是试图利用z寻找一个可解释的表达，于是将z进行了拆解，一个是噪声z，二是可解释的隐变量c，
#   而我们希望通过约束c与生成数据之间的关系，可以使得c里包含有对数据的可解释的信息。

#   如mnist数据集，c可以分为categorical latent code来表数字种类信息(0-9),以及continuous latent code来表示倾斜度，笔画粗细等等。
#   这些特征在数据空间中以一种复杂无序的方式进行编码，但如果这些特征是可分解的，则其将具有更强的可解释性，我们将更容易
#   利用这些特征进行编码。

# infoGAN设计
#   在训练期间，我们可任意分配一个先验c一张图片，实际上，我们可以根据需要添加任意数量的先验，infoGAN可能会为他们分配不同的属性，
#   infoGAN的作者称其为解开的表示，因为它将数据的属性分解为几个条件参数。
#   对于生成器，会给予一个或多个观测数据(或说是条件)c，即G(x,c);
#   判别器D(x)，即无条件判别器，输出真假判别向量、分类结果向量和条件输出c；
#   还需要训练一个网络Q(c|x)计算互信息，Q可以视作一个判别器，输出类别c。
# infoGAN的实现
#   同样使用MNIST数据，这里使用了三个隐含编码，c1用是个离散数字进行编码，每个类别的概率都是0.1；c2、c3连续编码，是-2到2的均匀分布。
#   观察发现，c2表示生成数字的旋转角度，c3表示生成数字的宽度，可通过图片显示，小的c2值数字向左偏，大的向右。
#   当遇到存在潜在的类别差别而没有标签数据，要使GAN能够在这类数据上拥有更好的表现，需要一类能够无监督辨别出这种潜在标签的数据，
#   infoGAN利用互信息对c进行约束。因为若c对于生成数据G(z,c)具有可解释性，则c和G(z,c)应具有高度相关性，即互信息大，若是无约束，
#   则他们之间没有特定关系，即互信息接近0，因此我们希望c与G(z,c)的互信息I(c;G(z,c))越大越好。
# 生成器-G
#   输入三个：输入噪声、条件变量(控制如数字的粗细等特征)、真实标签(需embedding),三者concatenate融合、卷积、输出一个生成图像；
#   损失：三个损失相加返回。计算生成图像和1之间的损失；判别器对生成图像的label输出与真实label损失、
#        G中输入的条件变量c0与D对输入的生成图像输出的条件输出c1(隐藏编码损失，越接近越好)
# 判别器-D
#   两个D，输入一个：分别为生成图像和真实图像；输出三个：分别为D1和D2的真假判别、分类判别向量与各自的条件输出c；
#   四个损失(两个真假判别、一个分类判别和一个隐含编码/条件损失)：真实和1之间的损失、虚假和0的损失、
#          D对真实图像的label判断输出和真实label、G中输入的条件变量c0与D对输入的生成图像输出的条件输出c1，四个相加返回






# 8 WGAN-Wasserstein GAN
#   稳定GAN的训练是非常重要的事情，原始GAN在训练中经常遇到一下问题：
#   1.模式崩溃，生成器生成非常窄的数据分布，仅覆盖数据分布中的单一模式，即生成器只能生成非常相似的样本(如MNIST中的单个数字)，即生成样本不多样；
#   2.没有指标可以说明收敛情况，生成器和判别器的loss没说明任何收敛相关信息，除非不时地手动监控生成数据判断。
#   总结：在原始的(近似)最优判别器下，生成器loss面临梯度消失，也面临优化目标荒谬，梯度不稳定，对多样性和准确性惩罚不平衡导致模型崩溃。

#   原始GAN模型崩溃的根源
#   1 等价优化的距离衡量(标准JS散度)不合理；
#   2 生成器随机初始化后的分布很难与真实分布有不可忽略的重叠。

# 原始GAN生成器梯度消失的原因
#   在(近似)最优判别器中，最小化生成器的loss等价于最小化真实图像与生成图像之间的JS散度，而由于该两者之间几乎不可能有不可忽略的重叠，
#   所以无论他们相距多远，JS散度都是常数log2，最终导致生成器的梯度(近似)为0，梯度消失。关键点在于如何评价生成图片和真实图片之间的距离。

# 解决问题的关键
#   使用Wasserstein距离，该距离优越性在于即使两个分布没有任何重叠，也可以反应他们之间的距离,即无论两个分布多远，都有梯度，都可以更新。

# WGAN实现-判别器越好,生成器梯度消失越严重
#   与原始GAN相比，只改了四点：1.判别器最后一层去掉sigmoid；2.生成器和判别器的loss不取log；
#   3.每次更新判别器的参数之后把他们的值/梯度截断到不超过一个固定常数c(因为控制了梯度，所以要更多的训练);
#   4.不用基于动量的优化算法(如momentum和adam)，推荐RMSProp(适合梯度不稳定的情况)

#   对于损失：D希望fake越小越好，real的越大越好，fake-real的值在输入优化器时越小越好；
#            G希望1-fake的值在输入优化器时越小越好，也就是希望fake越大越好。

#   Note：1.WGAN引入了W距离，其相当于KL散度与JS散度具有优越的平滑特性，理论上可解决梯度消失问题，接着通过数学变换将W距离写成可求解的形式，
#           利用一个参数数值范围受限的判别器神经网络来较大化这个形式，即可近似W距离。
#         2.WGAN既解决了训练不稳定的情况，也提供了一个可靠的训练指标，而且该指标确实与生成样本的质量高度相关。
# 生成器-G
#   输入为噪声；计算生成图像的判别结果和1之间的损失
# 判别器-D
#   两个D，输入分别为生成图像和真实图像；输出分别为分类别结果；一个损失-生成图片判别结果的平均值减去真实图片判别结果的平均值





# 9 SSGAN-这个的损失构建好像有问题
# 半监督学习生成对抗网络，利用GAN生成器生成的样本改进和提高图像分类任务的性能。
# 判别器
#   既扮演图像分类任务，又区分生成样本的真假。对于包含N类的数据，真实图像会被分到N个类别中，生成图像会被分到第N+1类中；
#   损失函数中引入huber loss。
# 生成器-G
#   输入为噪声，输出生成图像；计算生成图像的判别结果和0之间的损失
# 判别器-D
#   三个D，输入分别为噪声生成的生成图像、测试数据的真实图像(x_test)和训练数据的真实图像(y_test)；输出分别为分类别结果；
#   三个损失相加return：D对x_test的判别结果和y_test之间损失、D对x_train的判别结果和0之间损失、D对生成图像的判别结果和1之间损失





# 10 pix2pix GAN
#   主要用于图像之间的转换，又称图像翻译。普通的GAN接受的G的输入为随机向量，输出是图像；D接受图像，输出对或错，G、D联手生成真实图像。
#   设计
#       1.对于图像翻译任务，它的G输入应该是一张图x，输出也是一种图y，不需要添加随机输入；
#       2.对于图像翻译，G的输入和输出之间会共享很多信息，如轮廓信息等；图像上色的输入输出共享了边信息。为保证输入和输出相似度，加入L1loss
#       3.使用普通的CNN会导致每一层都承载保留着所有信息，容易出错。U-Net是变形的编码-解码模型，即将第i层拼接到第n-i层，
#          因为这两层图像大小一致，可认为承载着类似的信息。
#       4.为了保证生成图像真实且生成图像与输入图像匹配，D应输入成对的图像。pix2pix论文中的D被实现为patch-D，即无论生成的图像多大，
#         将其切分为多个固定大小的patch输入到D进行判断，这样设计使D的输入变小，计算量小，训练速度快。
# pix2pix论文中要点
#   输入为图像而不是随机向量；使用U-Net，跳跃连接来共享更多信息；Pair输入到D保证映射；Patch—D降低计算量提升效果；
#   L1损失函数的加入保证输入和输出之间的一致性。
# 数据集：Cityscapes城市景观数据主要包含在德国驾驶的车辆上拍摄的带标签视频，专注于对城市街道场景的语义理解。
#        2975张训练图，500张验证图，像素256x512，每张图片是一个组合，图像的左半部分是原始图片，右半部分是标记图片(语义分割输出)
# 生成器-G
#   输入一个：真实图像；输出：一个语义分割图像；
#   两个损失(相加返回)：计算D对生成图像的输出和1之间的损失；G的生成图像本身和真实语义分割图像本身(x_label)的平方差l1损失*lambda(lambda为10)
# 判别器-D
#   两个D，输入二个：分别为真实图像和语义分割图像、真实图像和生成图像；输出一个：分别为D1和D2的真假判别
#   两个损失：真实和1之间的损失、虚假和0的损失






# 11 cyclw GAN-batchsize为1,因为图像风格不同
#   cycle GAN主要用于图像之间的转换，如图像风格转换，适用于非配对的图像到图像转换，解决了模型需要成对数据进行训练的困难。
# 原理
#   将一类图片转换为另一类图片，即有两个样本空间，X、Y，希望将X空间中的样本转换为Y空间中的样本(获取一个数据集的特征，并转换为另一个数据集的特征)。
#   即实际的目标是学习X到Y的映射，设该映射为F，即生成器G。F可将X中的图片X转换为Y中的图片F(x)，对于生成的图片，D还需判断是否为真实图片，构成GAN。
#   总结：就是一个A到B的单向GAN加上一个B到A的单向GAN，两个GAN共享两个生成器，各带一个判别器，加起来共有两个G和和两个D。
#         另一个单向GAN有两个loss，cycleGAN有四个loss。

# 局限性
#   对颜色、纹理等的转换效果较好，对多样性高的、多变的转换效果不好(如几何转换)。

# 理论来说，对抗训练可学习和产生与目标域Y相同分布的输出，但会产生一些问题：
#   在足够大的样本容量下，网络可将相同的输入图像集合映射到目标域中图像的任何随机排列，其中任何学习的映射可以归纳出与目标分布匹配的输出分布，
#   即映射F完全可将所有X映射为Y空间中的同一张图片，使损失无效化。所以单独的对抗损失loss不能保证学习函数可将单个输入Xi映射到期望的输出Yi。
#   对此，作者提出了所谓的循环一致性损失(cycle consistency loss)

# 循环一致性损失原理
#   将x的图片转换到Y空间中，应该还可以转换回来，这样将杜绝模型将所有的X都转换为Y空间中的同一张图片。则需要两个生成器G_XY,G_YX。
#   为了训练该单向GAN需要两个loss，生成器的重建loss(希望生成的图片和原图尽可能相似)，判别器的判别loss(判断输入的图片是否是真是的Y空间图片)
# 生成器-G-两个G，但两个G的结构一样，用苹果生成橘子
#   G1：输入一个真实苹果去输出一个生成橘子，输入一个生成苹果去输出一个循环生成橘子
#   G1损失：有三个损失。损失器有两个(G损失器(仅使用一次，只输出一个损失)和循环损失器(使用二次,每次只输出一个损失))，
#           G损失器中计算1和生成的橘子之间损失；循环损失器1中计算真实苹果和循环苹果的损失；
#           循环损失器2中计算真实橘子和循环橘子的损失。三个损失相加为G1的损失

#   G2：输入一个生成橘子去输出一个循环生成苹果，输入一个真实橘子去输出一个生成苹果
#   G2损失：有三个损失。损失器有两个：G损失器(仅使用一次，只输出一个损失)、
#                                 循环损失器(使用二次,每次只输出一个损失，输入和输出与G1中的两个循环损失器相同，共用结果了))。
#           G损失器中计算1和生成苹果之间损失；循环损失器1中计算真实苹果和循环苹果的损失；
#           循环损失器2中计算真实橘子和循环橘子的损失。三个损失相加为G1的损失

# 判别器-D-两个D，但两个D的结构一样
#   D1：输入真实苹果去输出真实苹果的判别结果，输入生成苹果去输出生成苹果的判别结果
#   D1损失器：输出两个损失，return时相加输出。分别为1和真实苹果的损失、0和生成苹果损失

#   D2：输入真实橘子去输出真实橘子的判别结果，输入生成橘子去输出生成橘子的判别结果
#   D2损失器：输出两个损失，return时相加输出。分别为1和真实橘子损失、0和生成橘子损失








# 12 text2image
# 本质是一个RNN的词语向量化模型+条件GAN。首先利用一个RNN网络来将文字转换为向量，然后将生成的文本向量加入到G和D网络。
# Note:这里当图看上去挺真但与对应的描述不相符时，也要给予惩罚，否则D所能获得的信息仅仅是G的生成图，失去了判断图与描述是否相符的能力。
# 需要噪声输入：一般说一句话就是是描述内容的，而不是描述风格(背景、姿态等)。希望噪声起到这种加入风格的作用。从而生成更加真实多样化的图片。
#   另外通过特征可视化的方式，让z具有特定的风格加入功能，从而解决文本描述本身不对风格进行任何阐述的问题，随机化的z可加入不同的风格，
#   从而增加生成样本的真实性和多样性。



# 13 kaggle
#   2010年在墨尔本创立，主要为开发商和数据科学家提供举办机器学习竞赛，托管数据库、编写和分享代码的平台。
# kaggle的kaggle kernels相当于一个内置有浏览器的jupyter，即可在浏览器中运行jupyter的免费平台，其处理能力来自云端，不是本地机器。
# 用户可通过kaggle kernels免费使用NVidia K80 GPU。

# 注册：1.翻墙; 2.注册雅虎账号，用雅虎账号登录。



# 14 Wasserstein 距离
# 也叫Earth Mover's Distance，推土机距离，简称EMD，用来表示两个分布的相似程度。
# Wasserstein distance 衡量了把数据从分布p“移动成”分布q时所需要移动的平均距离的最小值
# （类似于把一堆土从一个形状移动到另一个形状所需要做的功的最小值）
#
# EMD是2000年IJCV期刊文章《The Earth Mover's Distance as a Metric for Image Retrieval》
# 提出的一种直方图相似度量（作者在之前的会议论文中也已经提到，不过鉴于IJCV的权威性和完整性，建议参考这篇文章）。
#
# 假设有两个工地P和Q，P工地上有m堆土，Q工地上有n个坑，现在要将P工地上的m堆土全部移动到Q工地上的n个坑中，所做的最小的功。
# 每堆土用一个二元组来表示(p,w)，p表土堆中心，w表土的数量。每个土堆中心pi到每个土坑中心qj都会有一个距离dij，则构成了一个m*n距离矩阵。
# 那么问题就是我们希望找到一个流（flow），当然也是个矩阵[fij]，每一项fij代表从pi到qj的流动数量，从而最小化整体的代价函数：
# 问题描述清楚了：就是把P中的m个坑的土，用最小的代价搬到Q中的n个坑中，pi到qj的两个坑的距离由dij来表示。fij是从pi搬到qj的土的量；
# dij是pi位置到qj位置的代价（距离）。要最小化WORK工作量。EMD是把这个工作量归一化以后的表达，即除以对fij的求和

# import scipy.stats
# import numpy as np
#
# P = np.array([3,5,2,1,3])
# Q = np.array([2,3,4,5,0])
# dists=[i for i in range(len(P))]
# D=scipy.stats.wasserstein_distance(P,Q,dists,dists)
# print(D)
